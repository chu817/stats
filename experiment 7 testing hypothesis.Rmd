---
title: "Gradient Descent"
author: "22MDT1067"
date: "2023-05-22"
output: html_document
---

```{r warning=FALSE}
library(ggplot2)
library(scales)
library(grid)
library(dplyr)

#cost function
formula = function(x) 1.2*(x-2)^2 + 3.2
# we visualize our function and the optimal solution
ggplot(data.frame(x = c(0,4)),aes(x)) + stat_function(fun = formula)+
  geom_point(data = data.frame(x=2,y =formula(2)),aes(x,y),color = "green",size=2)+
  ggtitle(expression(1.2*(x-2)^2 +3.2))

#first derivative
derivative = function(x) 2*1.2*(x-2)

# defining the alpha value (learning rate)
learning_rate =0.6
#defining the initial value
xold = 0.1
(iteration = data.frame(x=xold,y = formula(xold)))
## if we apply the parenthesis at start then only the iterationwill displayed in the output or else it would be stored in the environment

#one iteration

#apply the formula of gradient descent

xnew = xold - learning_rate*derivative(xold)

#output
rbind(iteration , c(xnew,formula(xnew)))

# defining epsilon i.e. the maximum iterations allowed

epsilon = 0.05
step=2 #already 2 steps are got in output
iteration = 10
# records the x and y values : add the initial guess
xtrace = list () ; ytrace = list()
xtrace[[1]] = xold; ytrace[[1]] = formula(xold)
xtrace[[2]] = xold; ytrace[[2]] = formula(xnew)
cbind(xtrace,ytrace)
while (abs(xnew-xold)> epsilon & step <=iteration){
  #update iteartion count
  step = step+1
  #gradient descent
  xold =  xnew
  xnew = xold -learning_rate*derivative(xold)
  #record keeping
  xtrace[[step]] = xnew
  ytrace[[step]] = formula(xnew)
  
}
#create the datapoints in the dataframe
record= data.frame(x=do.call(rbind,xtrace),y = do.call(rbind,ytrace))
record
         
```
